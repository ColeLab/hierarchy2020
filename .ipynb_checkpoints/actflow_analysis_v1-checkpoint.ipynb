{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity flow predictions should be better for regions with distributed processing\n",
    "#### Activity flow for each brain region across all conditions, and estimate total error\n",
    "#### Taku Ito\n",
    "1/3/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taku Ito\n",
    "# Script to compute connectivity decodability\n",
    "# 12/10/2019\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "# import statsmodels.sandbox.stats.multicomp as mc\n",
    "import sklearn\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import sys\n",
    "import taskGLMPipeline as tgp\n",
    "import h5py\n",
    "import dimensionality\n",
    "from importlib import reload\n",
    "import decoding\n",
    "import tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "#### Construct global variables\n",
    "## Exploratory subjects\n",
    "subjNums = ['178950','189450','199453','209228','220721','298455','356948','419239','499566','561444','618952','680452','757764','841349','908860',\n",
    "            '103818','113922','121618','130619','137229','151829','158035','171633','179346','190031','200008','210112','221319','299154','361234',\n",
    "            '424939','500222','570243','622236','687163','769064','845458','911849','104416','114217','122317','130720','137532','151930','159744',\n",
    "            '172029','180230','191235','200614','211316','228434','300618','361941','432332','513130','571144','623844','692964','773257','857263',\n",
    "            '926862','105014','114419','122822','130821','137633','152427','160123','172938','180432','192035','200917','211417','239944','303119',\n",
    "            '365343','436239','513736','579665','638049','702133','774663','865363','930449','106521','114823','123521','130922','137936','152831',\n",
    "            '160729','173334','180533','192136','201111','211619','249947','305830','366042','436845','516742','580650','645450','715041','782561',\n",
    "            '871762','942658','106824','117021','123925','131823','138332','153025','162026','173536','180735','192439','201414','211821','251833',\n",
    "            '310621','371843','445543','519950','580751','647858','720337','800941','871964','955465','107018','117122','125222','132017','138837',\n",
    "            '153227','162329','173637','180937','193239','201818','211922','257542','314225','378857','454140','523032','585862','654350','725751',\n",
    "            '803240','872562','959574','107422','117324','125424','133827','142828','153631','164030','173940','182739','194140','202719','212015',\n",
    "            '257845','316633','381543','459453','525541','586460','654754','727553','812746','873968','966975']\n",
    "\n",
    "## Validation subjects\n",
    "# subjNums = ['100206','108020','117930','126325','133928','143224','153934','164636','174437','183034','194443','204521','212823','268749','322224',\n",
    "#             '385450','463040','529953','587664','656253','731140','814548','877269','978578','100408','108222','118124','126426','134021','144832',\n",
    "#             '154229','164939','175338','185139','194645','204622','213017','268850','329844','389357','467351','530635','588565','657659','737960',\n",
    "#             '816653','878877','987074','101006','110007','118225','127933','134324','146331','154532','165638','175742','185341','195445','205119',\n",
    "#             '213421','274542','341834','393247','479762','545345','597869','664757','742549','820745','887373','989987','102311','111009','118831',\n",
    "#             '128632','135528','146432','154936','167036','176441','186141','196144','205725','213522','285345','342129','394956','480141','552241',\n",
    "#             '598568','671855','744553','826454','896879','990366','102513','112516','118932','129028','135629','146533','156031','167440','176845',\n",
    "#             '187850','196346','205826','214423','285446','348545','395756','481042','553344','599671','675661','749058','832651','899885','991267',\n",
    "#             '102614','112920','119126','129129','135932','147636','157336','168745','177645','188145','198350','208226','214726','286347','349244',\n",
    "#             '406432','486759','555651','604537','679568','749361','835657','901442','992774','103111','113316','120212','130013','136227','148133',\n",
    "#             '157437','169545','178748','188549','198451','208327','217429','290136','352738','414229','497865','559457','615744','679770','753150',\n",
    "#             '837560','907656','993675','103414','113619','120414','130114','136833','150726','157942','171330']\n",
    "\n",
    "basedir = '/projects/f_mc1689_1/NetworkDiversity/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt('/projects/f_mc1689_1/NetworkDiversity/data/network_partition.txt')\n",
    "# Need to flip networks\n",
    "networkdef = np.hstack((networkdef[180:],networkdef[:180]))\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = '//projects/f_mc1689_1/AnalysisTools/ParcelsGlasser2016/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = sorted(xticks.keys())\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']\n",
    "\n",
    "networkpalette = np.asarray(['mediumblue','slateblue','paleturquoise','darkmagenta','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab'])\n",
    "\n",
    "tasks = {'EMOTION':[0,1],\n",
    "         'GAMBLING':[2,3],\n",
    "         'LANGUAGE':[4,5],\n",
    "         'MOTOR':[6,7,8,9,10,11],\n",
    "         'RELATIONAL':[12,13],\n",
    "         'SOCIAL':[14,15],\n",
    "         'WM':[16,17,18,19,20,21,22,23]}\n",
    "taskNames = ['EMOTION', 'GAMBLING', 'LANGUAGE', 'MOTOR', 'RELATIONAL', 'SOCIAL', 'WM']\n",
    "TRsPerRun = [176,176,253,253,316,316,284,284,232,232,274,274,405,405]\n",
    "restRuns = ['rfMRI_REST1_RL', 'rfMRI_REST1_LR','rfMRI_REST2_RL', 'rfMRI_REST2_LR']\n",
    "taskRuns= ['tfMRI_EMOTION_RL','tfMRI_EMOTION_LR','tfMRI_GAMBLING_RL','tfMRI_GAMBLING_LR',\n",
    "           'tfMRI_LANGUAGE_RL','tfMRI_LANGUAGE_LR','tfMRI_MOTOR_RL','tfMRI_MOTOR_LR',\n",
    "           'tfMRI_RELATIONAL_RL','tfMRI_RELATIONAL_LR','tfMRI_SOCIAL_RL','tfMRI_SOCIAL_LR','tfMRI_WM_RL','tfMRI_WM_LR']\n",
    "\n",
    "model = '24pXaCompCorXVolterra'\n",
    "zscore = False\n",
    "FIR = False\n",
    "nTasks = 24\n",
    "\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in data for subject 1 / 176\n",
      "Loading in data for subject 26 / 176\n",
      "Loading in data for subject 51 / 176\n",
      "Loading in data for subject 76 / 176\n",
      "Loading in data for subject 101 / 176\n",
      "Loading in data for subject 126 / 176\n",
      "Loading in data for subject 151 / 176\n",
      "Loading in data for subject 176 / 176\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#######################################################################################################\n",
    "#### Load data\n",
    "task_activity = np.zeros((nParcels,nTasks,len(subjNums)))\n",
    "restfc = np.zeros((nParcels,nParcels,len(subjNums)))\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    if scount%25==0: print('Loading in data for subject', scount+1, '/', len(subjNums))\n",
    "    restfc[:,:,scount] = tools.loadMultRegFC(subj)\n",
    "    betas = []\n",
    "    for task in taskNames:\n",
    "        betas.extend(tools.loadTaskActivityParcels(subj,task,model='24pXaCompCorXVolterra').T)\n",
    "    betas = np.asarray(betas).T\n",
    "    task_activity[:,:,scount] = betas\n",
    "    scount += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run actflow for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "actflow_activity = np.zeros((nParcels,nTasks,len(subjNums)))\n",
    "scount = 0\n",
    "for subj in subjNums: \n",
    "    fc = restfc[:,:,scount]\n",
    "    np.fill_diagonal(fc,0)\n",
    "    tmp = np.matmul(task_activity[:,:,scount].T,fc)\n",
    "    actflow_activity[:,:,scount] = tmp.T\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save out activations and actflow predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('../../data/results/activations_actflow_analysis.h5','a')\n",
    "try: \n",
    "    h5f.create_dataset('real',data=task_activity)\n",
    "    h5f.create_dataset('actflow',data=actflow_activity)\n",
    "except:\n",
    "    del h5f['real'], h5f['actflow']\n",
    "    h5f.create_dataset('real',data=task_activity)\n",
    "    h5f.create_dataset('actflow',data=actflow_activity)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
